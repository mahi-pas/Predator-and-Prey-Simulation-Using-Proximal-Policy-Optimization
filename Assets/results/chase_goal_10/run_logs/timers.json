{
    "name": "root",
    "gauges": {
        "Runner.Policy.Entropy.mean": {
            "value": 1.4770007133483887,
            "min": 1.418668508529663,
            "max": 1.4856456518173218,
            "count": 200
        },
        "Runner.Policy.Entropy.sum": {
            "value": 7207.763671875,
            "min": 5856.263671875,
            "max": 8831.525390625,
            "count": 200
        },
        "Runner.Step.mean": {
            "value": 999942.0,
            "min": 4992.0,
            "max": 999942.0,
            "count": 200
        },
        "Runner.Step.sum": {
            "value": 999942.0,
            "min": 4992.0,
            "max": 999942.0,
            "count": 200
        },
        "Runner.Policy.ExtrinsicValueEstimate.mean": {
            "value": -26.50005340576172,
            "min": -72.59280395507812,
            "max": 0.013423298485577106,
            "count": 200
        },
        "Runner.Policy.ExtrinsicValueEstimate.sum": {
            "value": -1192.50244140625,
            "min": -5081.49609375,
            "max": 0.5503552556037903,
            "count": 200
        },
        "Runner.Losses.PolicyLoss.mean": {
            "value": 0.0776640715096922,
            "min": 0.05612596186175425,
            "max": 0.083822349687883,
            "count": 200
        },
        "Runner.Losses.PolicyLoss.sum": {
            "value": 0.1553281430193844,
            "min": 0.06614246222792038,
            "max": 0.2446924396014462,
            "count": 200
        },
        "Runner.Losses.ValueLoss.mean": {
            "value": 55.10639860232671,
            "min": 0.1218307904782705,
            "max": 87.19716084003448,
            "count": 200
        },
        "Runner.Losses.ValueLoss.sum": {
            "value": 110.21279720465343,
            "min": 0.1218307904782705,
            "max": 244.3069263299306,
            "count": 200
        },
        "Runner.Policy.LearningRate.mean": {
            "value": 8.022997326000029e-07,
            "min": 8.022997326000029e-07,
            "max": 0.0002987712004096,
            "count": 200
        },
        "Runner.Policy.LearningRate.sum": {
            "value": 1.6045994652000058e-06,
            "min": 1.6045994652000058e-06,
            "max": 0.0008890059036646999,
            "count": 200
        },
        "Runner.Policy.Epsilon.mean": {
            "value": 0.1002674,
            "min": 0.1002674,
            "max": 0.19959039999999997,
            "count": 200
        },
        "Runner.Policy.Epsilon.sum": {
            "value": 0.2005348,
            "min": 0.19938450000000005,
            "max": 0.5963353,
            "count": 200
        },
        "Runner.Policy.Beta.mean": {
            "value": 3.67132600000001e-05,
            "min": 3.67132600000001e-05,
            "max": 0.009959080960000002,
            "count": 200
        },
        "Runner.Policy.Beta.sum": {
            "value": 7.34265200000002e-05,
            "min": 7.34265200000002e-05,
            "max": 0.029633896469999997,
            "count": 200
        },
        "Runner.IsTraining.mean": {
            "value": 1.0,
            "min": 1.0,
            "max": 1.0,
            "count": 200
        },
        "Runner.IsTraining.sum": {
            "value": 1.0,
            "min": 1.0,
            "max": 1.0,
            "count": 200
        },
        "Runner.Environment.EpisodeLength.mean": {
            "value": 357.15384615384613,
            "min": 55.0,
            "max": 983.7333333333333,
            "count": 199
        },
        "Runner.Environment.EpisodeLength.sum": {
            "value": 4643.0,
            "min": 55.0,
            "max": 14756.0,
            "count": 199
        },
        "Runner.Environment.CumulativeReward.mean": {
            "value": -87.42244896521935,
            "min": -119.42551469802856,
            "max": -13.095239427354601,
            "count": 199
        },
        "Runner.Environment.CumulativeReward.sum": {
            "value": -1136.4918365478516,
            "min": -6789.24967956543,
            "max": -101.16309356689453,
            "count": 199
        },
        "Runner.Policy.ExtrinsicReward.mean": {
            "value": -87.42244896521935,
            "min": -119.42551469802856,
            "max": -13.095239427354601,
            "count": 199
        },
        "Runner.Policy.ExtrinsicReward.sum": {
            "value": -1136.4918365478516,
            "min": -6789.24967956543,
            "max": -101.16309356689453,
            "count": 199
        },
        "Tagger.Policy.Entropy.mean": {
            "value": 1.465030550956726,
            "min": 1.42041015625,
            "max": 1.518081784248352,
            "count": 200
        },
        "Tagger.Policy.Entropy.sum": {
            "value": 7149.34912109375,
            "min": 5893.5498046875,
            "max": 8840.6328125,
            "count": 200
        },
        "Tagger.Step.mean": {
            "value": 999942.0,
            "min": 4992.0,
            "max": 999942.0,
            "count": 200
        },
        "Tagger.Step.sum": {
            "value": 999942.0,
            "min": 4992.0,
            "max": 999942.0,
            "count": 200
        },
        "Tagger.Policy.ExtrinsicValueEstimate.mean": {
            "value": 23.630603790283203,
            "min": 0.22967812418937683,
            "max": 70.68106079101562,
            "count": 200
        },
        "Tagger.Policy.ExtrinsicValueEstimate.sum": {
            "value": 1063.377197265625,
            "min": 9.416803359985352,
            "max": 4947.67431640625,
            "count": 200
        },
        "Tagger.Losses.PolicyLoss.mean": {
            "value": 0.07727876387070864,
            "min": 0.0550135164327609,
            "max": 0.08096360377708657,
            "count": 200
        },
        "Tagger.Losses.PolicyLoss.sum": {
            "value": 0.1545575277414173,
            "min": 0.0702931211150523,
            "max": 0.24289081133125973,
            "count": 200
        },
        "Tagger.Losses.ValueLoss.mean": {
            "value": 62.96784096956253,
            "min": 0.10349249826200928,
            "max": 109.5169490178426,
            "count": 200
        },
        "Tagger.Losses.ValueLoss.sum": {
            "value": 125.93568193912506,
            "min": 0.10349249826200928,
            "max": 327.3535418510437,
            "count": 200
        },
        "Tagger.Policy.LearningRate.mean": {
            "value": 8.022997326000029e-07,
            "min": 8.022997326000029e-07,
            "max": 0.0002987712004096,
            "count": 200
        },
        "Tagger.Policy.LearningRate.sum": {
            "value": 1.6045994652000058e-06,
            "min": 1.6045994652000058e-06,
            "max": 0.0008890059036646999,
            "count": 200
        },
        "Tagger.Policy.Epsilon.mean": {
            "value": 0.1002674,
            "min": 0.1002674,
            "max": 0.19959039999999997,
            "count": 200
        },
        "Tagger.Policy.Epsilon.sum": {
            "value": 0.2005348,
            "min": 0.19938450000000005,
            "max": 0.5963353,
            "count": 200
        },
        "Tagger.Policy.Beta.mean": {
            "value": 3.67132600000001e-05,
            "min": 3.67132600000001e-05,
            "max": 0.009959080960000002,
            "count": 200
        },
        "Tagger.Policy.Beta.sum": {
            "value": 7.34265200000002e-05,
            "min": 7.34265200000002e-05,
            "max": 0.029633896469999997,
            "count": 200
        },
        "Tagger.IsTraining.mean": {
            "value": 1.0,
            "min": 1.0,
            "max": 1.0,
            "count": 200
        },
        "Tagger.IsTraining.sum": {
            "value": 1.0,
            "min": 1.0,
            "max": 1.0,
            "count": 200
        },
        "Tagger.Environment.EpisodeLength.mean": {
            "value": 357.15384615384613,
            "min": 55.0,
            "max": 983.7333333333333,
            "count": 199
        },
        "Tagger.Environment.EpisodeLength.sum": {
            "value": 4643.0,
            "min": 55.0,
            "max": 14756.0,
            "count": 199
        },
        "Tagger.Environment.CumulativeReward.mean": {
            "value": 72.15937111927913,
            "min": -2.940814169389861,
            "max": 116.68520203232765,
            "count": 199
        },
        "Tagger.Environment.CumulativeReward.sum": {
            "value": 938.0718245506287,
            "min": -20.585699185729027,
            "max": 6616.329673290253,
            "count": 199
        },
        "Tagger.Policy.ExtrinsicReward.mean": {
            "value": 72.15937111927913,
            "min": -2.940814169389861,
            "max": 116.68520203232765,
            "count": 199
        },
        "Tagger.Policy.ExtrinsicReward.sum": {
            "value": 938.0718245506287,
            "min": -20.585699185729027,
            "max": 6616.329673290253,
            "count": 199
        }
    },
    "metadata": {
        "timer_format_version": "0.1.0",
        "start_time_seconds": "1682219625",
        "python_version": "3.7.16 (default, Jan 17 2023, 16:06:28) [MSC v.1916 64 bit (AMD64)]",
        "command_line_arguments": "C:\\Users\\pasarm\\anaconda3\\envs\\ml-agents-2.0.1\\Scripts\\mlagents-learn Config/config.yaml --run-id=chase_goal_10",
        "mlagents_version": "0.29.0",
        "mlagents_envs_version": "0.29.0",
        "communication_protocol_version": "1.5.0",
        "pytorch_version": "1.13.1+cu117",
        "numpy_version": "1.21.2",
        "end_time_seconds": "1682223484"
    },
    "total": 3858.6738191,
    "count": 1,
    "self": 0.021568000000115717,
    "children": {
        "run_training.setup": {
            "total": 0.1417887000000002,
            "count": 1,
            "self": 0.1417887000000002
        },
        "TrainerController.start_learning": {
            "total": 3858.5104624,
            "count": 1,
            "self": 3.271165399963138,
            "children": {
                "TrainerController._reset_env": {
                    "total": 17.5305654,
                    "count": 1,
                    "self": 17.5305654
                },
                "TrainerController.advance": {
                    "total": 3837.505890300037,
                    "count": 66001,
                    "self": 1.6063600000329643,
                    "children": {
                        "env_step": {
                            "total": 3835.8995303000042,
                            "count": 66001,
                            "self": 3267.273169900045,
                            "children": {
                                "SubprocessEnvManager._take_step": {
                                    "total": 567.1670199000108,
                                    "count": 66001,
                                    "self": 17.135545500023,
                                    "children": {
                                        "TorchPolicy.evaluate": {
                                            "total": 550.0314743999878,
                                            "count": 125112,
                                            "self": 96.1502595999599,
                                            "children": {
                                                "TorchPolicy.sample_actions": {
                                                    "total": 453.8812148000279,
                                                    "count": 125112,
                                                    "self": 453.8812148000279
                                                }
                                            }
                                        }
                                    }
                                },
                                "workers": {
                                    "total": 1.4593404999483646,
                                    "count": 66001,
                                    "self": 0.0,
                                    "children": {
                                        "worker_root": {
                                            "total": 3836.9742872000043,
                                            "count": 66001,
                                            "is_parallel": true,
                                            "self": 1108.6311992999758,
                                            "children": {
                                                "steps_from_proto": {
                                                    "total": 0.005171100000001871,
                                                    "count": 2,
                                                    "is_parallel": true,
                                                    "self": 0.0004886000000006163,
                                                    "children": {
                                                        "_process_rank_one_or_two_observation": {
                                                            "total": 0.004682500000001255,
                                                            "count": 8,
                                                            "is_parallel": true,
                                                            "self": 0.004682500000001255
                                                        }
                                                    }
                                                },
                                                "UnityEnvironment.step": {
                                                    "total": 2728.3379168000283,
                                                    "count": 66001,
                                                    "is_parallel": true,
                                                    "self": 45.54792959994302,
                                                    "children": {
                                                        "UnityEnvironment._generate_step_input": {
                                                            "total": 57.3944940000344,
                                                            "count": 66001,
                                                            "is_parallel": true,
                                                            "self": 57.3944940000344
                                                        },
                                                        "communicator.exchange": {
                                                            "total": 2504.9506373000186,
                                                            "count": 66001,
                                                            "is_parallel": true,
                                                            "self": 2504.9506373000186
                                                        },
                                                        "steps_from_proto": {
                                                            "total": 120.4448559000323,
                                                            "count": 132002,
                                                            "is_parallel": true,
                                                            "self": 30.039283700088177,
                                                            "children": {
                                                                "_process_rank_one_or_two_observation": {
                                                                    "total": 90.40557219994412,
                                                                    "count": 528008,
                                                                    "is_parallel": true,
                                                                    "self": 90.40557219994412
                                                                }
                                                            }
                                                        }
                                                    }
                                                }
                                            }
                                        }
                                    }
                                }
                            }
                        }
                    }
                },
                "trainer_threads": {
                    "total": 8.720000005268957e-05,
                    "count": 1,
                    "self": 8.720000005268957e-05,
                    "children": {
                        "thread_root": {
                            "total": 0.0,
                            "count": 0,
                            "is_parallel": true,
                            "self": 0.0,
                            "children": {
                                "trainer_advance": {
                                    "total": 7675.9218250000395,
                                    "count": 245275,
                                    "is_parallel": true,
                                    "self": 21.25361659999271,
                                    "children": {
                                        "process_trajectory": {
                                            "total": 4300.779629000052,
                                            "count": 245275,
                                            "is_parallel": true,
                                            "self": 4299.922363700052,
                                            "children": {
                                                "RLTrainer._checkpoint": {
                                                    "total": 0.8572653000001083,
                                                    "count": 4,
                                                    "is_parallel": true,
                                                    "self": 0.8572653000001083
                                                }
                                            }
                                        },
                                        "_update_policy": {
                                            "total": 3353.8885793999943,
                                            "count": 940,
                                            "is_parallel": true,
                                            "self": 731.1116693999884,
                                            "children": {
                                                "TorchPPOOptimizer.update": {
                                                    "total": 2622.776910000006,
                                                    "count": 45570,
                                                    "is_parallel": true,
                                                    "self": 2622.776910000006
                                                }
                                            }
                                        }
                                    }
                                }
                            }
                        }
                    }
                },
                "TrainerController._save_models": {
                    "total": 0.20275409999976546,
                    "count": 1,
                    "self": 0.0586859000000004,
                    "children": {
                        "RLTrainer._checkpoint": {
                            "total": 0.14406819999976506,
                            "count": 2,
                            "self": 0.14406819999976506
                        }
                    }
                }
            }
        }
    }
}